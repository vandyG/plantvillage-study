\section{Related Work}
\subsection{Current Landscape of CNN Architectures in Image Classification}
The evolution of CNN architectures defines the current landscape of image classification research. This progression can be broadly categorized based on their primary design philosophies.
\begin{enumerate}
    \item \textbf{Foundational and Depth-Focused Architectures:} Early breakthroughs, such as AlexNet (2012) and VGGNet (2014), established the effectiveness of deep networks, particularly demonstrating that increasing network depth using simple $3 \times 3$ convolutional filters generally enhances performance. VGGNet is still widely utilized for feature extraction in transfer learning due to its simple and uniform structure. \cite{MajeedZangana2024,cong2023review,chen2021review,sharma2022deep}
    \item \textbf{Architectures Mitigating Training Difficulties:} The pursuit of greater depth encountered optimization challenges, notably the vanishing gradient problem. ResNet (Residual Network) successfully addressed this in 2015 by introducing identity mapping via skip connections, allowing the training of extremely deep architectures (up to 152 layers or more) while maintaining or improving accuracy. Building on this concept, DenseNet utilized dense connections between all previous layers to foster feature reuse and enhance gradient flow, thereby improving computational efficiency and reducing the parameter count. Concurrently, Inception architectures (GoogLeNet) explored increasing network \textit{width} using a multi-branch structure with parallel convolutional operations of varying kernel sizes, aiming for effective multi-scale feature capture while employing sparse connections for computational efficiency.\cite{MajeedZangana2024, zhao2024review, trigka2025comprehensive}
    \item \textbf{Lightweight and Efficient Architectures:} For deployment in resource-constrained environments, such as mobile or edge devices prevalent in agricultural settings, specialized architectures emerged prioritizing computational speed and minimized parameter counts (FLOPs). Key examples include MobileNet, which employs depth-wise separable convolutions; ShuffleNet, which utilizes channel shuffling; and EfficientNet, which leverages a compound scaling method to uniformly balance network depth, width, and resolution.\cite{zhao2024review,MajeedZangana2024,chen2021review}
    \item \textbf{Attention-Based and Hybrid Models:} Recent advancements integrate attention mechanisms to prioritize salient feature representations. SENet (Squeeze-and-Excitation Networks) introduced channel-wise attention, significantly improving performance with marginal computational overhead. The emergence of Vision Transformers (ViTs) demonstrated the capacity of self-attention to model global dependencies by treating images as sequences of patches, offering superior performance in holistic image analysis. Modern architectures like ConvNext seek to bridge this gap, integrating the macro-design principles of ViTs while maintaining the inductive bias and computational efficiency of traditional CNNs.\cite{chen2021review,zhao2024review,trigka2025comprehensive}
\end{enumerate}

\subsection{CNN Applications and Research Gaps in Plant Disease Detection (PDD)}
In practical domains like agriculture, CNNs are extensively applied for PDD, enabling tasks such as crop monitoring, pest spotting, and yield prediction by analyzing imagery captured from various sources (e.g., drones, remote sensors, and cameras). PDD research commonly leverages large-scale, publicly available benchmark datasets, most notably the PlantVillage dataset, which comprises numerous images of various crops categorized by specific diseases. Given the necessity to minimize data annotation and computational training costs, the \textbf{transfer learning} paradigm—where models pre-trained on massive general datasets (like ImageNet) are fine-tuned for the specific PDD task—has become the standard methodology.\cite{MajeedZangana2024,chen2021review,trigka2025comprehensive}

However, existing literature often focuses predominantly on optimizing multi-class classification accuracy (identifying specific diseases) on laboratory-collected datasets. A critical issue identified is that models trained on the PlantVillage dataset, which contains images collected under highly controlled conditions with uniform backgrounds, often demonstrate poor generalization when deployed in real-world agricultural settings exhibiting domain shifts (e.g., varying illumination, complex natural backgrounds, and sensor noise).

\subsection{Differentiation of the Current Research}
This research, differs significantly from existing literature in both scope and rigorous validation methodology, specifically addressing the practical challenges of deployment in agricultural informatics:
\begin{enumerate}
    \item \textbf{Comprehensive Architectural Scope:} We systematically evaluate and compare a broad spectrum of pretrained CNN models, ranging from established deep architectures (e.g., VGG16, ResNet50, DenseNet-121, Inception V4, Xception) to contemporary efficient and lightweight designs (e.g., MobileNet, ShuffleNet, MnasNet1, EfficientNet-Lite4, ConvNext). This breadth allows for identifying not only the most accurate models but also those offering the best balance between accuracy and computational efficiency (measured via inference speed), which is paramount for practical edge deployment.
    \item \textbf{Reframing the Classification Task:} Instead of focusing purely on multi-class disease differentiation, this study recasts the problem into a crucial \textbf{binary classification} task: distinguishing "healthy" from "unhealthy" leaves. This shift, though seemingly simpler, demands sophisticated techniques to mitigate the aggravated class imbalance and the risk of overfitting to spurious cues. We employ targeted data augmentation (including replacing majority class images with augmented variants to encourage learning disease-relevant features rather than background artifacts) and batch-wise balanced sampling to ensure robust training.
    \item \textbf{Cross-Dataset Generalization Validation:} Crucially, we move beyond reporting performance solely on the clean, in-distribution PlantVillage test set. We deploy a \textbf{cross-dataset evaluation} strategy using the independent PlantDoc dataset. The PlantDoc dataset, derived from internet-scraped images, inherently possesses the real-world domain variations (natural backgrounds, diverse lighting) that models trained on PlantVillage typically fail to generalize to. This robust evaluation, measured using comprehensive metrics (including precision, recall, F1-score, AUC-ROC, sensitivity, and specificity), provides a realistic assessment of model deployability and robustness to environmental shifts—a critical but often overlooked metric in prior PDD studies.
\end{enumerate}