\section{Results}
\label{sec:results}

\subsection{PlantVillage Dataset Evaluation}

Table~\ref{tab:plantvillage-results} summarizes the performance metrics for all evaluated models on the PlantVillage test set. The results reveal several important findings regarding the effectiveness of different architectural approaches for plant disease detection.

\subsubsection{Classical Models Analysis}

The classical architectures demonstrated surprisingly strong performance despite their relatively simpler design. VGG16 achieved the highest AUC-ROC score of 0.9990 among all models, with an accuracy of 97.05\% and F1-score of 0.9801. The model exhibited excellent recall (99.85\%), indicating near-perfect sensitivity in detecting diseased samples. AlexNet, despite being the earliest architecture evaluated, achieved 96.53\% accuracy with remarkable training efficiency (538.35 seconds), making it highly suitable for resource-constrained deployment scenarios.

\subsubsection{Lightweight Models Analysis}

Among the lightweight architectures, EfficientNet-Lite4 emerged as the top performer overall, achieving the highest accuracy (98.20\%) and F1-score (0.9875) across all evaluated models. This result validates the efficacy of compound scaling strategies employed in the EfficientNet family. MobileNet\_v2 also demonstrated competitive performance with 96.17\% accuracy while maintaining computational efficiency suitable for mobile deployment.

However, lightweight models exhibited greater variance in performance. SqueezeNet1\_0 and MnasNet1\_0 showed lower accuracy (82.01\% and 84.22\% respectively), though both maintained high AUC-ROC scores ($>$0.97), indicating good ranking capability despite suboptimal classification thresholds. The confusion matrix analysis reveals that these models tend toward high recall at the expense of precision, suggesting a bias toward predicting the diseased class.

\subsubsection{Modern Architectures Analysis}

Modern architectures presented mixed results. ResNet50 and DenseNet121 achieved strong performance (97.09\% and 96.76\% accuracy respectively), benefiting from their sophisticated connectivity patterns that facilitate gradient flow and feature reuse. Both models demonstrated excellent precision ($>$0.99), indicating low false positive rates critical for practical deployment.

Interestingly, ConvNeXt\_Base, despite being the most recently developed architecture, achieved only 91.03\% accuracy. Similarly, Xception and InceptionV4 showed lower accuracy (87.66\% and 88.09\%) compared to classical alternatives, with notably lower precision values.

\subsection{Training Dynamics Analysis}

Figure~\ref{fig:train-loss} presents the training and validation loss curves across all model clusters. Several observations emerge from this analysis:

\textbf{Classical Models:} Both AlexNet and VGG16 demonstrated smooth convergence with training and validation losses decreasing consistently across epochs. The gap between training and validation loss remained minimal, suggesting good generalization without significant overfitting.

\textbf{Lightweight Models:} These architectures showed more varied convergence patterns. EfficientNet-Lite4 exhibited rapid initial convergence, while MnasNet1\_0 showed higher validation losses that plateau at suboptimal values, explaining their lower test accuracy. MobileNet\_v2 and ShuffleNet\_v2 converge reasonably well.

\textbf{Modern Architectures:} ResNet50 and DenseNet121 displayed stable learning dynamics with low final loss values. However, InceptionV4 showed elevated validation loss despite low training loss, indicating potential overfitting on the PlantVillage dataset.

\subsection{ROC Curve Analysis}

The ROC curves in Figure~\ref{fig:roc-plantvillage} provide insight into the classification capability across different operating thresholds. All models achieved AUC-ROC values exceeding 0.93, indicating strong discriminative ability for the binary classification task.

VGG16 and AlexNet demonstrated near-perfect ROC curves that closely hug the upper-left corner, reflecting their exceptional ability to distinguish healthy from diseased samples across all threshold values. Among lightweight models, EfficientNet-Lite4 showed the steepest initial rise, achieving high true positive rates at very low false positive rates.



\subsection{Cross-Dataset Generalization: PlantDoc Evaluation}
Table~\ref{tab:plantdoc-results} presents the performance metrics when models trained on PlantVillage were evaluated on the PlantDoc dataset without fine-tuning.

\subsubsection{Generalization Performance Analysis}

\textbf{ConvNeXt emerged as the best generalizing model} with 83.90\% accuracy and the highest F1-score (0.8782) on PlantDoc. Notably, this represents a ranking reversal from PlantVillage results, where ConvNeXt ranked lower. This suggests that ConvNeXt's modern design captures more generalizable disease features that transfer across datasets.

\textbf{Classical models demonstrated robust generalization.} AlexNet achieved 81.36\% accuracy on PlantDoc (compared to 96.53\% on PlantVillage), representing only a 15.2 percentage point drop. VGG16 showed similar robustness with 75.42\% accuracy. The simpler feature hierarchies learned by classical networks appear to transfer better to out-of-distribution samples.

\textbf{Severe degradation in lightweight models.} MobileNet\_v2 dropped from 96.17\% to 44.49\% accuracy, while ShuffleNet\_v2 fell to 40.25\%. The results reveal extreme prediction bias: ShuffleNet\_v2 achieved perfect precision (1.0) but only 3.42\% recall, indicating it classified nearly all samples as healthy. This behavior suggests these models overfit to PlantVillage-specific background and lighting patterns.

\textbf{ResNet50's catastrophic failure} (32.63\% accuracy, below random baseline for some classes) is particularly notable given its strong PlantVillage performance. The AUC-ROC of 0.2811 (below 0.5) indicates inverted predictions, where the model's probability rankings are negatively correlated with true labels.

\subsubsection{ROC Analysis on PlantDoc}

ConvNeXt, SqueezeNet1\_0, and VGG16 maintained reasonable ROC curves with AUC values above 0.90, indicating preserved ranking ability despite lower classification accuracy. However, ResNet50's ROC curve falls below the diagonal random classifier line, confirming systematic prediction errors. Among lightweight models, only SqueezeNet1\_0 (AUC=0.909) maintained strong discriminative capability on PlantDoc. See Figure~\ref{fig:roc-plantdoc}.
% \subsection{Confusion Matrix Analysis}

% The confusion matrices (Figures~\ref{fig:cm-classical}, \ref{fig:cm-lightweight}, \ref{fig:cm-modern}) reveal distinct error patterns across model categories.

% % \begin{figure}[H]
% %     \centering
% %     \includegraphics[width=\linewidth]{sec/Images/confusion_matrices_all_models.png}
% %     \caption{Confusion Matrices for All Models on PlantVillage}
% %     \label{fig:cm-all}
% % \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\linewidth]{sec/Images/confusion_matrices_classical_models.png}
%     \caption{Confusion Matrices - Classical Models}
%     \label{fig:cm-classical}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\linewidth]{sec/Images/confusion_matrices_lightweight_models.png}
%     \caption{Confusion Matrices - Lightweight Models}
%     \label{fig:cm-lightweight}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\linewidth]{sec/Images/confusion_matrices_modern_architecture.png}
%     \caption{Confusion Matrices - Modern Architectures}
%     \label{fig:cm-modern}
% \end{figure}

% On PlantVillage, models generally exhibit high true positive and true negative counts with minimal off-diagonal errors. VGG16 and EfficientNet-Lite4 show the most balanced confusion matrices with low counts in both false positive and false negative cells.

% Modern architectures including Xception, InceptionV4, and ConvNeXt show elevated false positive counts (987, 940, and 727 respectively), indicating over-prediction of the diseased class. This pattern persists across thresholds and may reflect learned biases from the class-balanced augmentation strategy.

\subsection{Computational Efficiency}

Table~\ref{tab:computational} presents inference speed measurements.

AlexNet processes 182.0 samples/second, balancing speed with strong generalization performance (81.36\% accuracy on PlantDoc). VGG16, despite achieving 75.42\% accuracy on PlantDoc, maintains practical throughput at 152.6 samples/second.

ConvNeXt\_Base, while demonstrating the best cross-dataset generalization (83.90\% accuracy), requires significantly more computational resources with only 96.9 samples/second---nearly half the speed of the fastest models. This trade-off between accuracy and inference speed is critical for deployment.

% The inference measurements reveal that model complexity does not always correlate with computational cost on small batches. DenseNet121 achieves competitive speed (165.3 samples/second) despite its dense connectivity, while tf\_efficientnet\_lite4 is notably slower (149.4 samples/second) than other lightweight architectures, likely due to compound scaling overhead.

