{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c2b46a",
   "metadata": {},
   "source": [
    "\n",
    "# Multi-Model Training & Profiling\n",
    "Complete binary PlantVillage comparison (MobileNetV2, EfficientNetB0, ResNet50, VGG16, DenseNet121, InceptionV3) with timing and memory stats. Optimized defaults for M3 Pro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743d5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "\n",
    "def get_memory_usage():\n",
    "    info = {\"ram_gb\": None, \"gpu_current_gb\": None, \"gpu_peak_gb\": None}\n",
    "    try:\n",
    "        import psutil\n",
    "        process = psutil.Process(os.getpid())\n",
    "        info[\"ram_gb\"] = process.memory_info().rss / (1024 ** 3)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        mem_info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "        info[\"gpu_current_gb\"] = mem_info[\"current\"] / (1024 ** 3)\n",
    "        info[\"gpu_peak_gb\"] = mem_info[\"peak\"] / (1024 ** 3)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "\n",
    "def reset_gpu_memory_stats():\n",
    "    try:\n",
    "        tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f00d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring TensorFlow for M3 Pro...\n",
      "✓ Metal GPU acceleration enabled: 1 GPU(s) found\n",
      "TensorFlow version: 2.16.2\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Global config\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "EPOCHS = 10\n",
    "SEED = 42\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "print(\"Configuring TensorFlow for M3 Pro...\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✓ Metal GPU acceleration enabled: {len(gpus)} GPU(s) found\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"⚠ No GPU found - training will use CPU (slower)\")\n",
    "\n",
    "# Tune threading for the M3 Pro CPU\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(8)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f4a1d",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data loading and binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c0a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_split_plant_village(seed=SEED):\n",
    "    plant_village_data, info = tfds.load(\n",
    "        \"plant_village\", with_info=True, as_supervised=True\n",
    "    )\n",
    "    if len(plant_village_data) == 1 and \"train\" in plant_village_data:\n",
    "        full_train = plant_village_data[\"train\"]\n",
    "        total_size = sum(1 for _ in full_train)\n",
    "        train_size = int(0.7 * total_size)\n",
    "        val_size = int(0.15 * total_size)\n",
    "        full_train = full_train.shuffle(total_size, seed=seed)\n",
    "        train_ds = full_train.take(train_size)\n",
    "        val_ds = full_train.skip(train_size).take(val_size)\n",
    "        test_ds = full_train.skip(train_size + val_size)\n",
    "        plant_village_data = {\n",
    "            \"train\": train_ds,\n",
    "            \"validation\": val_ds,\n",
    "            \"test\": test_ds,\n",
    "        }\n",
    "    return plant_village_data, info\n",
    "\n",
    "\n",
    "def make_binary_labels(plant_village_data, info):\n",
    "    label_names = info.features[\"label\"].names\n",
    "    binary_lookup = np.array(\n",
    "        [\n",
    "            0 if name.split(\"___\", 1)[-1].lower() == \"healthy\" else 1\n",
    "            for name in label_names\n",
    "        ],\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "    binary_lookup_tf = tf.constant(binary_lookup)\n",
    "\n",
    "    def to_binary_label(image, label):\n",
    "        label = tf.cast(label, tf.int32)\n",
    "        binary_label = tf.gather(binary_lookup_tf, label)\n",
    "        return image, binary_label\n",
    "\n",
    "    binary_data = {\n",
    "        split: ds.map(to_binary_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        for split, ds in plant_village_data.items()\n",
    "    }\n",
    "\n",
    "    train_original = plant_village_data[\"train\"]\n",
    "    counts = defaultdict(lambda: {\"healthy\": 0, \"diseased\": 0})\n",
    "    for _, label in tfds.as_numpy(train_original):\n",
    "        label_str = info.features[\"label\"].int2str(int(label))\n",
    "        plant_type, disease_name = label_str.split(\"___\", 1)\n",
    "        if disease_name.lower() == \"healthy\":\n",
    "            counts[plant_type][\"healthy\"] += 1\n",
    "        else:\n",
    "            counts[plant_type][\"diseased\"] += 1\n",
    "\n",
    "    total_healthy = sum(v[\"healthy\"] for v in counts.values())\n",
    "    total_diseased = sum(v[\"diseased\"] for v in counts.values())\n",
    "    return binary_data, total_healthy, total_diseased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c4285",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Augmentation and balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40b0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_augmented_train_ds(binary_data, total_healthy, total_diseased):\n",
    "    train_ds = binary_data[\"train\"]\n",
    "    healthy_label = 0\n",
    "    diseased_label = 1\n",
    "\n",
    "    healthy_ds = train_ds.filter(lambda _, lbl: tf.equal(lbl, healthy_label))\n",
    "    diseased_ds = train_ds.filter(lambda _, lbl: tf.equal(lbl, diseased_label))\n",
    "\n",
    "    def augment_healthy(image, label):\n",
    "        image_f = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image_f = tf.image.random_flip_left_right(image_f)\n",
    "        image_f = tf.image.random_flip_up_down(image_f)\n",
    "        image_f = tf.image.rot90(\n",
    "            image_f,\n",
    "            tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32),\n",
    "        )\n",
    "        image_f = tf.image.random_saturation(image_f, 0.8, 1.25)\n",
    "        image_f = tf.image.random_hue(image_f, 0.05)\n",
    "        image_f = tf.image.random_brightness(image_f, 0.12)\n",
    "        image_f = tf.image.random_contrast(image_f, 0.8, 1.25)\n",
    "        image_f = tf.clip_by_value(image_f, 0.0, 1.0)\n",
    "        image_aug = tf.image.convert_image_dtype(image_f, tf.uint8)\n",
    "        return image_aug, label\n",
    "\n",
    "    def augment_diseased_with_replacement(image, label):\n",
    "        image_f = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "        def augmented():\n",
    "            aug = tf.image.random_flip_left_right(image_f)\n",
    "            aug = tf.image.rot90(\n",
    "                aug, tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)\n",
    "            )\n",
    "            aug = tf.image.random_contrast(aug, 0.9, 1.1)\n",
    "            aug = tf.image.random_brightness(aug, 0.08)\n",
    "            aug = tf.image.random_hue(aug, 0.03)\n",
    "            aug = tf.clip_by_value(aug, 0.0, 1.0)\n",
    "            return tf.image.convert_image_dtype(aug, tf.uint8)\n",
    "\n",
    "        def original():\n",
    "            return image\n",
    "\n",
    "        choice = tf.random.uniform([], 0.0, 1.0)\n",
    "        return tf.cond(choice > 0.5, augmented, original), label\n",
    "\n",
    "    healthy_multiplier = 0\n",
    "    if total_healthy > 0:\n",
    "        healthy_multiplier = max(1, math.ceil(total_diseased / total_healthy) - 1)\n",
    "\n",
    "    augmented_healthy_datasets = [healthy_ds]\n",
    "    for _ in range(healthy_multiplier):\n",
    "        augmented_healthy_datasets.append(\n",
    "            healthy_ds.map(augment_healthy, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        )\n",
    "\n",
    "    healthy_augmented_ds = augmented_healthy_datasets[0]\n",
    "    for ds in augmented_healthy_datasets[1:]:\n",
    "        healthy_augmented_ds = healthy_augmented_ds.concatenate(ds)\n",
    "\n",
    "    healthy_augmented_ds = healthy_augmented_ds.shuffle(4096)\n",
    "\n",
    "    diseased_augmented_ds = diseased_ds.map(\n",
    "        augment_diseased_with_replacement, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    augmented_train_ds = healthy_augmented_ds.concatenate(diseased_augmented_ds)\n",
    "    augmented_train_ds = augmented_train_ds.shuffle(8192).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    binary_data[\"train\"] = augmented_train_ds\n",
    "    return binary_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cad5e2",
   "metadata": {},
   "source": [
    "\n",
    "## 3) tf.data prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45153e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataset(ds, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE):\n",
    "    autotune = tf.data.AUTOTUNE\n",
    "\n",
    "    def preprocess(image, label):\n",
    "        image = tf.image.resize(image, image_size)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image, label\n",
    "\n",
    "    return (\n",
    "        ds.map(preprocess, num_parallel_calls=autotune)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(autotune)\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_all_splits(binary_data):\n",
    "    train_ds = prepare_dataset(binary_data[\"train\"])\n",
    "    val_ds = prepare_dataset(binary_data[\"validation\"])\n",
    "    test_ds = prepare_dataset(binary_data[\"test\"])\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f98c8",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Model factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c94b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_binary_classifier(base_model_fn, input_shape=(224, 224, 3)):\n",
    "    base_model = base_model_fn(\n",
    "        input_shape=input_shape, include_top=False, weights=\"imagenet\"\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_builder(model_key):\n",
    "    key = model_key.lower()\n",
    "    if key == \"mobilenet_v2\":\n",
    "        return lambda: create_binary_classifier(tf.keras.applications.MobileNetV2)\n",
    "    if key == \"efficientnet_b0\":\n",
    "        return lambda: create_binary_classifier(tf.keras.applications.EfficientNetB0)\n",
    "    if key == \"resnet50\":\n",
    "        return lambda: create_binary_classifier(tf.keras.applications.ResNet50)\n",
    "    if key == \"vgg16\":\n",
    "        return lambda: create_binary_classifier(tf.keras.applications.VGG16)\n",
    "    if key == \"densenet121\":\n",
    "        return lambda: create_binary_classifier(tf.keras.applications.DenseNet121)\n",
    "    if key == \"inception_v3\":\n",
    "        return lambda: create_binary_classifier(tf.keras.applications.InceptionV3)\n",
    "    raise ValueError(f\"Unknown model key: {model_key}\")\n",
    "\n",
    "\n",
    "MODELS_TO_TRAIN = [\n",
    "    # \"mobilenet_v2\",\n",
    "    # \"efficientnet_b0\",\n",
    "    \"resnet50\"\n",
    "    # \"vgg16\",\n",
    "    # \"densenet121\",\n",
    "    # \"inception_v3\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33306e82",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Training helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6a8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_model(model, lr=1e-3):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_single_model(model_key, train_ds, val_ds, epochs=EPOCHS):\n",
    "    builder = get_model_builder(model_key)\n",
    "    model = builder()\n",
    "    compile_model(model)\n",
    "\n",
    "    num_params = model.count_params()\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = os.path.join(\"logs\", f\"{model_key}_{timestamp}\")\n",
    "    ckpt_path = os.path.join(\"models\", f\"{model_key}_{timestamp}_best.h5\")\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            ckpt_path, monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=2, verbose=1, min_lr=1e-6\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    reset_gpu_memory_stats()\n",
    "    mem_before = get_memory_usage()\n",
    "    t0 = time.time()\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    t1 = time.time()\n",
    "    mem_after = get_memory_usage()\n",
    "\n",
    "    train_time_sec = t1 - t0\n",
    "\n",
    "    return model, history, ckpt_path, num_params, train_time_sec, mem_before, mem_after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e97a3",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Evaluation helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24207767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, test_ds, model_key):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_proba = []\n",
    "\n",
    "    for images, labels in test_ds:\n",
    "        probs = model.predict(images, verbose=0).flatten()\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        y_proba.extend(probs)\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_proba = np.array(y_proba)\n",
    "\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_proba)\n",
    "    except ValueError:\n",
    "        auc = np.nan\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Healthy\", \"Diseased\"],\n",
    "        yticklabels=[\"Healthy\", \"Diseased\"],\n",
    "    )\n",
    "    plt.title(f\"{model_key} - Confusion Matrix\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    cm_path = os.path.join(\"models\", f\"{model_key}_confusion_matrix.png\")\n",
    "    plt.savefig(cm_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"{model_key} Test Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"test_accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"auc\": auc,\n",
    "        \"cm_path\": cm_path,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c8850",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Run training & collect results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb1cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 13:35:08.921419: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-11-27 13:35:08.921453: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-11-27 13:35:08.921456: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.66 GB\n",
      "2025-11-27 13:35:08.921474: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-27 13:35:08.921486: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-27 13:35:12.529265: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-11-27 13:35:19.734561: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 13:35:25.707189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-27 13:35:37.395942: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:76: Filling up shuffle buffer (this may take a while): 6490 of 8192\n",
      "2025-11-27 13:35:37.788232: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    856/Unknown \u001b[1m159s\u001b[0m 167ms/step - accuracy: 0.9630 - auc: 0.1083 - loss: 0.0712"
     ]
    }
   ],
   "source": [
    "\n",
    "plant_village_data, info = load_and_split_plant_village()\n",
    "binary_data, total_healthy, total_diseased = make_binary_labels(plant_village_data, info)\n",
    "binary_data = build_augmented_train_ds(binary_data, total_healthy, total_diseased)\n",
    "train_ds, val_ds, test_ds = prepare_all_splits(binary_data)\n",
    "\n",
    "all_results = []\n",
    "histories = {}\n",
    "\n",
    "for model_key in MODELS_TO_TRAIN:\n",
    "    model, history, ckpt_path, num_params, train_time_sec, mem_before, mem_after = (\n",
    "        train_single_model(model_key, train_ds, val_ds, epochs=EPOCHS)\n",
    "    )\n",
    "\n",
    "    metrics = evaluate_model(model, test_ds, model_key)\n",
    "\n",
    "    def mem_dict_to_flat(prefix, d):\n",
    "        return {\n",
    "            f\"{prefix}_ram_gb\": d.get(\"ram_gb\"),\n",
    "            f\"{prefix}_gpu_current_gb\": d.get(\"gpu_current_gb\"),\n",
    "            f\"{prefix}_gpu_peak_gb\": d.get(\"gpu_peak_gb\"),\n",
    "        }\n",
    "\n",
    "    row = {\n",
    "        \"model\": model_key,\n",
    "        \"num_params\": num_params,\n",
    "        \"train_time_sec\": train_time_sec,\n",
    "        \"train_time_min\": train_time_sec / 60.0,\n",
    "        \"checkpoint_path\": ckpt_path,\n",
    "    }\n",
    "    row.update(mem_dict_to_flat(\"mem_before\", mem_before))\n",
    "    row.update(mem_dict_to_flat(\"mem_after\", mem_after))\n",
    "    row.update(metrics)\n",
    "\n",
    "    all_results.append(row)\n",
    "    histories[model_key] = history\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "csv_path = os.path.join(\"results\", \"model_comparison.csv\")\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Model comparison table saved to: {csv_path}\")\n",
    "print(results_df[[\"model\", \"test_accuracy\", \"f1\", \"auc\", \"train_time_min\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e24263d",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Comparison plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_bar_metric(df, metric, ylabel, title, filename):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x = np.arange(len(df))\n",
    "    plt.bar(x, df[metric])\n",
    "    plt.xticks(x, df[\"model\"], rotation=30, ha=\"right\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(\"results\", filename)\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "results_df_sorted = results_df.sort_values(\"test_accuracy\", ascending=False)\n",
    "\n",
    "plot_bar_metric(\n",
    "    results_df_sorted,\n",
    "    \"test_accuracy\",\n",
    "    \"Accuracy\",\n",
    "    \"Test Accuracy by Model\",\n",
    "    \"accuracy_by_model.png\",\n",
    ")\n",
    "\n",
    "plot_bar_metric(\n",
    "    results_df_sorted,\n",
    "    \"f1\",\n",
    "    \"F1-score\",\n",
    "    \"F1-score by Model\",\n",
    "    \"f1_by_model.png\",\n",
    ")\n",
    "\n",
    "plot_bar_metric(\n",
    "    results_df_sorted,\n",
    "    \"auc\",\n",
    "    \"AUC\",\n",
    "    \"ROC-AUC by Model\",\n",
    "    \"auc_by_model.png\",\n",
    ")\n",
    "\n",
    "plot_bar_metric(\n",
    "    results_df_sorted,\n",
    "    \"train_time_min\",\n",
    "    \"Minutes\",\n",
    "    \"Training Time (min) by Model\",\n",
    "    \"train_time_by_model.png\",\n",
    ")\n",
    "\n",
    "if results_df_sorted[\"mem_after_ram_gb\"].notna().any():\n",
    "    plot_bar_metric(\n",
    "        results_df_sorted,\n",
    "        \"mem_after_ram_gb\",\n",
    "        \"GB\",\n",
    "        \"RAM Usage After Training by Model\",\n",
    "        \"ram_usage_by_model.png\",\n",
    "    )\n",
    "\n",
    "if results_df_sorted[\"mem_after_gpu_peak_gb\"].notna().any():\n",
    "    plot_bar_metric(\n",
    "        results_df_sorted,\n",
    "        \"mem_after_gpu_peak_gb\",\n",
    "        \"GB\",\n",
    "        \"GPU Peak Memory by Model\",\n",
    "        \"gpu_peak_by_model.png\",\n",
    "    )\n",
    "\n",
    "print(\"All training, evaluation, and comparison complete.\")\n",
    "print(\"Check models/ for checkpoints, results/ for CSV & plots, logs/ for TensorBoard.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
