{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7edfba2",
   "metadata": {},
   "source": [
    "\n",
    "# PyTorch Training\n",
    "Train frozen-backbone torch models on the same preprocessed PlantVillage dataset (no augmentation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99182bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "PREPROCESSED_DIR = PROJECT_ROOT / \"preprocessed\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ecc4b",
   "metadata": {},
   "source": [
    "## 1) Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79122022",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantVillageCSVDataset(Dataset):\n",
    "    def __init__(self, split, img_dir, csv_path, transform=None):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # filter by split column if your CSV has train/val/test info\n",
    "        self.df = df[df[\"split\"] == split].reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform if transform else T.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.img_dir / row[\"filename\"]\n",
    "        label = torch.tensor(row[\"label\"], dtype=torch.float32)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "IS_MAC = sys.platform == \"darwin\"\n",
    "WORKERS = 0 if IS_MAC else 4\n",
    "\n",
    "def make_loader(split):\n",
    "    dataset = PlantVillageCSVDataset(\n",
    "        split=split,\n",
    "        img_dir=PREPROCESSED_DIR / \"images\",\n",
    "        csv_path=PREPROCESSED_DIR / \"labels.csv\",\n",
    "        transform=T.Compose([\n",
    "            T.Resize((224,224)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                      shuffle=(split==\"train\"),\n",
    "                      num_workers=0 if IS_MAC else 4,\n",
    "                      pin_memory=not IS_MAC)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = make_loader(\"train\")\n",
    "val_loader = make_loader(\"val\")\n",
    "test_loader = make_loader(\"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aad62d",
   "metadata": {},
   "source": [
    "## 2) Model: ResNet50 (Frozen Backbone)\n",
    "Load ImageNet-pretrained ResNet50, freeze the convolutional backbone, and replace the final classifier with a single-logit layer for binary classification (diseased vs healthy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "def build_model(model_name, freeze_backbone=True):\n",
    "    model_name = model_name.lower()\n",
    "\n",
    "    # --- torchvision models ---\n",
    "    if model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, 1)\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(4096, 1)\n",
    "\n",
    "    elif model_name == \"vgg16\":\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(4096, 1)\n",
    "\n",
    "    elif model_name == \"densenet121\":\n",
    "        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "\n",
    "    elif model_name == \"googlenet\":\n",
    "        model = models.googlenet(weights=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    elif model_name == \"inception_v3\":\n",
    "        model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    # --- timm models ---\n",
    "    else:\n",
    "        import timm\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=1)\n",
    "\n",
    "    if freeze_backbone:\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"fc\" not in name and \"classifier\" not in name and \"head\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# Build model, criterion, optimizer\n",
    "model_key = \"resnet50\"\n",
    "model = get_resnet50_binary(freeze_backbone=True).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# Only optimize classifier head parameters\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "best_path = MODELS_DIR / f\"{model_key}_best.pt\"\n",
    "print(f\"Model: {model_key}, frozen_backbone=True, saving to: {best_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2c4f5",
   "metadata": {},
   "source": [
    "## 3) Train/eval helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b649350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images).squeeze(1)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(images).squeeze(1)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    return {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred)),\n",
    "        \"auc\": float(roc_auc_score(y_true, y_prob)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9c60f",
   "metadata": {},
   "source": [
    "## 4) Run training/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13702852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training alexnet ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /Users/pratyaksh/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:08<00:00, 29.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.1307, val_f1=0.9817\n",
      "Epoch 2: train_loss=0.0672, val_f1=0.9850\n",
      "Epoch 3: train_loss=0.0566, val_f1=0.9863\n",
      "Epoch 4: train_loss=0.0502, val_f1=0.9918\n",
      "Epoch 5: train_loss=0.0473, val_f1=0.9886\n",
      "{'framework': 'pytorch', 'model': 'alexnet', 'accuracy': 0.9868647188804321, 'precision': 0.9893975092561427, 'recall': 0.992571332095222, 'f1': 0.9909818794774548, 'auc': 0.9989285195395186, 'train_time_sec': 1907.5788941383362, 'train_time_min': 31.79298156897227, 'checkpoint': '/Users/pratyaksh/UTA/sem3/CV/plantvillage-study/notebooks/models/alexnet.pt'}\n",
      "Saved PyTorch metrics -> /Users/pratyaksh/UTA/sem3/CV/plantvillage-study/notebooks/results/pytorch_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framework</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>train_time_sec</th>\n",
       "      <th>train_time_min</th>\n",
       "      <th>checkpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>0.986865</td>\n",
       "      <td>0.989398</td>\n",
       "      <td>0.992571</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>1907.578894</td>\n",
       "      <td>31.792982</td>\n",
       "      <td>/Users/pratyaksh/UTA/sem3/CV/plantvillage-stud...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  framework    model  accuracy  precision    recall        f1       auc  \\\n",
       "0   pytorch  alexnet  0.986865   0.989398  0.992571  0.990982  0.998929   \n",
       "\n",
       "   train_time_sec  train_time_min  \\\n",
       "0     1907.578894       31.792982   \n",
       "\n",
       "                                          checkpoint  \n",
       "0  /Users/pratyaksh/UTA/sem3/CV/plantvillage-stud...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_model(model, loader, criterion=None):\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(images).squeeze(1)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            if criterion is not None:\n",
    "                loss = criterion(logits, labels)\n",
    "                total_loss += loss.item() * images.size(0)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "            n += images.size(0)\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred)),\n",
    "        \"auc\": float(roc_auc_score(y_true, y_prob)),\n",
    "    }\n",
    "    if criterion is not None:\n",
    "        metrics[\"loss\"] = total_loss / max(1, n)\n",
    "    return metrics\n",
    "\n",
    "# Training loop tuned to match TF notebook behaviour\n",
    "PATIENCE = 2\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "t0 = time.time()\n",
    "best_val_acc = -1.0\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_metrics = eval_model(model, val_loader, criterion=criterion)\n",
    "    val_loss = val_metrics.get('loss', float('inf'))\n",
    "    val_acc = val_metrics['accuracy']\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}, val_f1={val_metrics['f1']:.4f}\")\n",
    "\n",
    "    # ModelCheckpoint: save best by val_accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "\n",
    "    # Scheduler step on val_loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # EarlyStopping on val_loss\n",
    "    if val_loss < best_val_loss - 1e-6:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping: no improvement in val_loss for {PATIENCE} epochs.\")\n",
    "        break\n",
    "\n",
    "# Load best model and evaluate on test set\n",
    "if best_path.exists():\n",
    "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "\n",
    "test_metrics = eval_model(model, test_loader, criterion=criterion)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
