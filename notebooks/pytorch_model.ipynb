{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7edfba2",
   "metadata": {},
   "source": [
    "\n",
    "# PyTorch Training\n",
    "Train frozen-backbone torch models on the same preprocessed PlantVillage dataset (no augmentation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e1b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "GPU/Accelerator: Apple MPS\n",
      "\n",
      "================================================================================\n",
      "Training: vgg16\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (vgg16):  13%|█▎        | 274/2114 [01:28<09:58,  3.07it/s, batch_loss=0.0609] "
     ]
    }
   ],
   "source": [
    "import os, time, psutil, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from tqdm import tqdm   # NEW\n",
    "\n",
    "# ======================================================\n",
    "# CONFIG\n",
    "# ======================================================\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "PATIENCE = 2\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "NPY_DIR = ROOT / \"preprocessed_numpy\"\n",
    "RESULTS_DIR = ROOT / \"results\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ======================================================\n",
    "# DEVICE \n",
    "# ======================================================\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_total = torch.cuda.get_device_properties(0).total_memory / (1024**2)\n",
    "    gpu_used = torch.cuda.memory_allocated() / (1024**2)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    gpu_name = \"Apple MPS\"\n",
    "    gpu_total = 0\n",
    "    gpu_used = 0\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpu_name = \"CPU\"\n",
    "    gpu_total = 0\n",
    "    gpu_used = 0\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "print(\"GPU/Accelerator:\", gpu_name)\n",
    "\n",
    "# ======================================================\n",
    "# DATASET\n",
    "# ======================================================\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.images = np.load(NPY_DIR / f\"{split}_images.npy\")\n",
    "        self.labels = np.load(NPY_DIR / f\"{split}_labels.npy\")\n",
    "        self.transform = T.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.images[idx]), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def make_loader(split):\n",
    "    return DataLoader(\n",
    "        NumpyDataset(split),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=(split == \"train\"),\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(\"train\")\n",
    "val_loader = make_loader(\"val\")\n",
    "test_loader = make_loader(\"test\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MODEL BUILDER\n",
    "# ======================================================\n",
    "def build_model(name, freeze_backbone=True):\n",
    "    lname = name.lower()\n",
    "\n",
    "    if lname == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    elif lname == \"alexnet\":\n",
    "        model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(4096, 1)\n",
    "\n",
    "    elif lname == \"vgg16\":\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(4096, 1)\n",
    "\n",
    "    elif lname == \"densenet121\":\n",
    "        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "\n",
    "    elif lname == \"googlenet\":\n",
    "        model = models.googlenet(weights=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    elif lname == \"inception_v3\":\n",
    "        model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    elif lname == \"shufflenet_v2\":\n",
    "        model = models.shufflenet_v2_x1_0(weights=models.ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    elif lname == \"mobilenet_v2\":\n",
    "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "\n",
    "\n",
    "    else:\n",
    "        import timm\n",
    "        model = timm.create_model(lname, pretrained=True, num_classes=1)\n",
    "\n",
    "    if freeze_backbone:\n",
    "        for n, p in model.named_parameters():\n",
    "            if \"fc\" not in n and \"classifier\" not in n and \"head\" not in n:\n",
    "                p.requires_grad = False\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# METRICS\n",
    "# ======================================================\n",
    "def eval_metrics(model, loader, criterion=None, return_raw=False):\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    total_loss, n = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X).squeeze(1)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            if criterion:\n",
    "                total_loss += criterion(logits, y).item() * X.size(0)\n",
    "\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "            n += X.size(0)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "    try: auc = roc_auc_score(y_true, y_prob)\n",
    "    except: auc = float(\"nan\")\n",
    "\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_prob)\n",
    "\n",
    "    if return_raw:\n",
    "        return y_true, y_prob, fpr, tpr, thr\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / n if criterion else None,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"auc\": auc,\n",
    "        \"roc_fpr\": fpr,\n",
    "        \"roc_tpr\": tpr,\n",
    "        \"roc_thresh\": thr,\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# TRAINING LOOP WITH tqdm\n",
    "# ======================================================\n",
    "def train_models(models_to_train):\n",
    "    out_path = RESULTS_DIR / \"metrics.csv\"\n",
    "\n",
    "    for name in models_to_train:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Training: {name}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        model = build_model(name)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=1)\n",
    "\n",
    "        best_loss = float(\"inf\")\n",
    "        best_path = MODELS_DIR / f\"{name}_best.pth\"\n",
    "        no_improve = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "            # tqdm progress bar for batches\n",
    "            batch_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} ({name})\", leave=False)\n",
    "\n",
    "            model.train()\n",
    "            total_loss, n = 0.0, 0\n",
    "\n",
    "            for X, y in batch_bar:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(X).squeeze(1)\n",
    "                loss = criterion(logits, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                n += X.size(0)\n",
    "                batch_bar.set_postfix({\"batch_loss\": loss.item()})\n",
    "\n",
    "            train_loss = total_loss / n\n",
    "            val_m = eval_metrics(model, val_loader, criterion)\n",
    "            val_loss = val_m[\"loss\"]\n",
    "\n",
    "            print(f\"[{name}] Epoch {epoch} | Train {train_loss:.4f} | Val {val_loss:.4f} | Acc={val_m['accuracy']:.4f}\")\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), best_path)\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "            if no_improve >= PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        # Final evaluation\n",
    "        model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "        val_m = eval_metrics(model, val_loader, criterion)\n",
    "        test_m = eval_metrics(model, test_loader, criterion)\n",
    "        _, _, fpr, tpr, thr = eval_metrics(model, test_loader, criterion, return_raw=True)\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        mem = psutil.Process(os.getpid()).memory_info().rss / (1024**2)\n",
    "        gpu_used = torch.cuda.memory_allocated() / (1024**2) if torch.cuda.is_available() else 0\n",
    "\n",
    "        row = {\n",
    "            \"model\": name,\n",
    "\n",
    "            \"val_loss\": val_m[\"loss\"],\n",
    "            \"val_accuracy\": val_m[\"accuracy\"],\n",
    "            \"val_precision\": val_m[\"precision\"],\n",
    "            \"val_recall\": val_m[\"recall\"],\n",
    "            \"val_f1\": val_m[\"f1\"],\n",
    "            \"val_auc\": val_m[\"auc\"],\n",
    "\n",
    "            \"test_loss\": test_m[\"loss\"],\n",
    "            \"test_accuracy\": test_m[\"accuracy\"],\n",
    "            \"test_precision\": test_m[\"precision\"],\n",
    "            \"test_recall\": test_m[\"recall\"],\n",
    "            \"test_f1\": test_m[\"f1\"],\n",
    "            \"test_auc\": test_m[\"auc\"],\n",
    "\n",
    "            \"roc_fpr\": json.dumps(fpr.tolist()),\n",
    "            \"roc_tpr\": json.dumps(tpr.tolist()),\n",
    "            \"roc_thresholds\": json.dumps(thr.tolist()),\n",
    "\n",
    "            \"train_time_sec\": elapsed,\n",
    "            \"memory_mb\": mem,\n",
    "            \"gpu_name\": gpu_name,\n",
    "            \"gpu_total_memory_mb\": gpu_total,\n",
    "            \"gpu_used_memory_mb\": gpu_used,\n",
    "        }\n",
    "\n",
    "        # Append/Update CSV\n",
    "        new_df = pd.DataFrame([row])\n",
    "\n",
    "        if out_path.exists():\n",
    "            old_df = pd.read_csv(out_path)\n",
    "            old_df = old_df[old_df[\"model\"] != name]\n",
    "            updated_df = pd.concat([old_df, new_df], ignore_index=True)\n",
    "            updated_df.to_csv(out_path, index=False)\n",
    "            print(f\"Updated CSV: {out_path}\")\n",
    "            display(updated_df)\n",
    "        else:\n",
    "            new_df.to_csv(out_path, index=False)\n",
    "            print(f\"Created CSV: {out_path}\")\n",
    "            display(new_df)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# RUN\n",
    "# ======================================================\n",
    "models_to_train = [\n",
    "    # ============================\n",
    "    # Classic CNNs\n",
    "    # ============================\n",
    "\n",
    "    # \"alexnet\",                # Classic CNN  | pratyaksh done\n",
    "    \"vgg16\",                  # Classic CNN  | Prartyaksh\n",
    "    # \"resnet50\",               # Classic CNN  | Pratyaksh\n",
    "    # \"googlenet\",              # Classic CNN (Inception V1) | Pratyaksh done\n",
    "    # \"densenet121\",            # Classic CNN (Dense connections) | Pratyaksh\n",
    "\n",
    "    # ============================\n",
    "    # Lightweight Architectures\n",
    "    # ============================\n",
    "\n",
    "    # \"mobilenet_v2\",           # Lightweight CNN | Pratyaksh done\n",
    "    # \"shufflenet_v2\",          # Lightweight CNN | Pratyaksh done\n",
    "    # \"squeezenet1_0\",          # Lightweight CNN (Fire modules) | Pratyaksh\n",
    "    # \"mnasnet1_0\",             # Lightweight CNN (NAS-designed) | Pratyaksh\n",
    "    # \"tf_efficientnet_lite4\",  # Lightweight CNN (EfficientNet-Lite) | Pratyaksh done\n",
    "\n",
    "    # ============================\n",
    "    # Deep / Modern Architectures\n",
    "    # ============================\n",
    "\n",
    "    # \"inception_v4\",           # Deep CNN (Inception series) | Vandit\n",
    "    # \"inception_resnet_v2\",    # Deep CNN (Inception + ResNet hybrid) | Vandit\n",
    "    # \"xception\",               # Deep CNN (Depthwise separable conv) | Vandit\n",
    "    # \"seresnet50\",             # Deep CNN (ResNet + Squeeze-and-Excitation) | Vandit\n",
    "    # \"seresnext50_32x4d\",      # Deep CNN (ResNeXt + SE attention) | Vandit\n",
    "    # \"regnet_y_800mf\",         # Deep CNN (Facebook RegNet scalable design) | Vandit\n",
    "    # \"convnext_base\",          # Deep CNN (ConvNeXt — CNN inspired by ViT) | Vandit\n",
    "\n",
    "    # ============================\n",
    "    # Hybrid CNN + Attention\n",
    "    # ============================\n",
    "\n",
    "    # \"maxvit_base_tf_224\",     # Hybrid CNN + Attention (MaxViT)\n",
    "]\n",
    "\n",
    "\n",
    "train_models(models_to_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd7b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
