{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e37a8e7",
   "metadata": {},
   "source": [
    "\n",
    "# Preprocessing — Static Augmented Dataset Builder\n",
    "Build a balanced, augmented PlantVillage binary dataset (0=healthy, 1=diseased) and save RGB PNGs + CSV labels for TensorFlow and PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676e7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Resize target\n",
    "IMAGE_SIZE = (224, 224)\n",
    "DATASET_NAME = \"plant_village\"\n",
    "\n",
    "# Directory structure\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "PREPROCESSED_DIR = PROJECT_ROOT / \"preprocessed\"\n",
    "PREPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    (PREPROCESSED_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "print(\"TensorFlow GPU:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75f8b2",
   "metadata": {},
   "source": [
    "## 1) Load & binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29cf31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 19:35:53.793500: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='plant_village',\n",
      "    full_name='plant_village/1.0.2',\n",
      "    description=\"\"\"\n",
      "    The PlantVillage dataset consists of 54303 healthy and unhealthy leaf images\n",
      "    divided into 38 categories by species and disease.\n",
      "    \n",
      "    NOTE: The original dataset is not available from the original source\n",
      "    (plantvillage.org), therefore we get the unaugmented dataset from a paper that\n",
      "    used that dataset and republished it. Moreover, we dropped images with\n",
      "    Background_without_leaves label, because these were not present in the original\n",
      "    dataset.\n",
      "    \n",
      "    Original paper URL: https://arxiv.org/abs/1511.08060 Dataset URL:\n",
      "    https://data.mendeley.com/datasets/tywbtsjrjv/1\n",
      "    \"\"\",\n",
      "    homepage='https://arxiv.org/abs/1511.08060',\n",
      "    data_dir='/Users/pratyaksh/tensorflow_datasets/plant_village/1.0.2',\n",
      "    file_format=tfrecord,\n",
      "    download_size=827.82 MiB,\n",
      "    dataset_size=815.37 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "        'image/filename': Text(shape=(), dtype=string),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=38),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    nondeterministic_order=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=54303, num_shards=8>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/HughesS15,\n",
      "      author    = {David P. Hughes and\n",
      "                   Marcel Salath{\\'{e}}},\n",
      "      title     = {An open access repository of images on plant health to enable the\n",
      "                   development of mobile disease diagnostics through machine\n",
      "                   learning and crowdsourcing},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1511.08060},\n",
      "      year      = {2015},\n",
      "      url       = {http://arxiv.org/abs/1511.08060},\n",
      "      archivePrefix = {arXiv},\n",
      "      eprint    = {1511.08060},\n",
      "      timestamp = {Mon, 13 Aug 2018 16:48:21 +0200},\n",
      "      biburl    = {https://dblp.org/rec/bib/journals/corr/HughesS15},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n",
      "ORIGINAL TRAIN — healthy=10646, diseased=27366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 19:36:02.579860: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "def load_and_split_plant_village(seed=SEED):\n",
    "    data, info = tfds.load(DATASET_NAME, with_info=True, as_supervised=True)\n",
    "    \n",
    "    if len(data) == 1 and \"train\" in data:\n",
    "        full = data[\"train\"]\n",
    "        total_size = sum(1 for _ in full)\n",
    "        train_size = int(0.7 * total_size)\n",
    "        val_size = int(0.15 * total_size)\n",
    "\n",
    "        full = full.shuffle(total_size, seed=seed, reshuffle_each_iteration=False)\n",
    "        train_ds = full.take(train_size)\n",
    "        val_ds = full.skip(train_size).take(val_size)\n",
    "        test_ds = full.skip(train_size + val_size)\n",
    "\n",
    "        data = {\"train\": train_ds, \"val\": val_ds, \"test\": test_ds}\n",
    "\n",
    "    return data, info\n",
    "\n",
    "\n",
    "plant_data, info = load_and_split_plant_village()\n",
    "\n",
    "print(info)\n",
    "def make_binary_labels(dataset_splits, info):\n",
    "    label_names = info.features[\"label\"].names\n",
    "    \n",
    "    binary_lookup = np.array(\n",
    "        [0 if name.split(\"___\",1)[-1].lower()==\"healthy\" else 1\n",
    "         for name in label_names],\n",
    "        dtype=np.int32\n",
    "    )\n",
    "    lookup_tf = tf.constant(binary_lookup)\n",
    "\n",
    "    def to_binary(image, label):\n",
    "        return image, tf.gather(lookup_tf, tf.cast(label, tf.int32))\n",
    "\n",
    "    binary = {\n",
    "        split: ds.map(to_binary, num_parallel_calls=AUTOTUNE)\n",
    "        for split, ds in dataset_splits.items()\n",
    "    }\n",
    "\n",
    "    # Count original healthy/diseased\n",
    "    counts = defaultdict(lambda: {\"healthy\": 0, \"diseased\": 0})\n",
    "    for _, label in tfds.as_numpy(dataset_splits[\"train\"]):\n",
    "        s = info.features[\"label\"].int2str(int(label))\n",
    "        plant, disease = s.split(\"___\", 1)\n",
    "        if disease.lower() == \"healthy\":\n",
    "            counts[plant][\"healthy\"] += 1\n",
    "        else:\n",
    "            counts[plant][\"diseased\"] += 1\n",
    "\n",
    "    total_healthy = sum(v[\"healthy\"] for v in counts.values())\n",
    "    total_diseased = sum(v[\"diseased\"] for v in counts.values())\n",
    "\n",
    "    print(f\"ORIGINAL TRAIN — healthy={total_healthy}, diseased={total_diseased}\")\n",
    "    return binary, total_healthy, total_diseased\n",
    "\n",
    "\n",
    "binary_data, total_healthy, total_diseased = make_binary_labels(plant_data, info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc46495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_healthy(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # spatial\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k)\n",
    "\n",
    "    # color jitter strong\n",
    "    image = tf.image.random_saturation(image, 0.7, 1.4)\n",
    "    image = tf.image.random_hue(image, 0.05)\n",
    "    image = tf.image.random_brightness(image, 0.15)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.3)\n",
    "\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "\n",
    "def augment_diseased(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # spatial mild\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k)\n",
    "\n",
    "    # color jitter mild\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    image = tf.image.random_brightness(image, 0.08)\n",
    "    image = tf.image.random_hue(image, 0.03)\n",
    "\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "\n",
    "def augment_diseased_with_replacement(image, label):\n",
    "    \"\"\"50% keep original, 50% mildly augment.\"\"\"\n",
    "    do_aug = tf.random.uniform([]) > 0.5\n",
    "    aug = augment_diseased(image)\n",
    "    return tf.cond(do_aug, lambda: (aug, label), lambda: (image, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c5779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 19:36:09.524777: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded into memory: healthy=10646, diseased=27366\n",
      "Healthy multiplier: 3x\n"
     ]
    }
   ],
   "source": [
    "def build_balanced_train_dataset(train_ds, total_healthy, total_diseased):\n",
    "    healthy_images = []\n",
    "    diseased_images = []\n",
    "\n",
    "    # Step 1: Extract images into arrays\n",
    "    for img, lbl in tfds.as_numpy(train_ds):\n",
    "        if lbl == 0:\n",
    "            healthy_images.append(img)\n",
    "        else:\n",
    "            diseased_images.append(img)\n",
    "\n",
    "    healthy_count = len(healthy_images)\n",
    "    diseased_count = len(diseased_images)\n",
    "\n",
    "    print(f\"Loaded into memory: healthy={healthy_count}, diseased={diseased_count}\")\n",
    "\n",
    "    # Step 2: Augment healthy to match diseased count\n",
    "    multiplier = math.ceil(diseased_count / healthy_count)\n",
    "    print(f\"Healthy multiplier: {multiplier}x\")\n",
    "\n",
    "    augmented_healthy = []\n",
    "    for _ in range(multiplier):\n",
    "        for img in healthy_images:\n",
    "            augmented_healthy.append(augment_healthy(img))\n",
    "\n",
    "    # Now clip to exactly diseased_count\n",
    "    augmented_healthy = augmented_healthy[:diseased_count]\n",
    "\n",
    "    # Step 3: Diseased (mild augmentation w/ replacement)\n",
    "    augmented_diseased = []\n",
    "    for img in diseased_images:\n",
    "        aug, _ = augment_diseased_with_replacement(img, tf.constant(1, tf.int32))\n",
    "        augmented_diseased.append(aug.numpy())\n",
    "\n",
    "    assert len(augmented_healthy) == len(augmented_diseased)\n",
    "\n",
    "    print(f\"FINAL balanced count: {len(augmented_healthy)} healthy, {len(augmented_diseased)} diseased\")\n",
    "\n",
    "    # Combine\n",
    "    final_images = augmented_healthy + augmented_diseased\n",
    "    final_labels = [0] * len(augmented_healthy) + [1] * len(augmented_diseased)\n",
    "\n",
    "    # Shuffle\n",
    "    idx = np.arange(len(final_images))\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    final_images = [final_images[i] for i in idx]\n",
    "    final_labels = [final_labels[i] for i in idx]\n",
    "\n",
    "    return final_images, final_labels\n",
    "\n",
    "\n",
    "final_train_images, final_train_labels = build_balanced_train_dataset(\n",
    "    binary_data[\"train\"], total_healthy, total_diseased\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a45190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_split(images, labels, split_name):\n",
    "    split_dir = PREPROCESSED_DIR / split_name\n",
    "    split_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    rows = []\n",
    "    for i, (img, label) in enumerate(zip(images, labels)):\n",
    "        fname = f\"{split_name}_{i:06d}.png\"\n",
    "        path = split_dir / fname\n",
    "        encoded = tf.io.encode_png(img)\n",
    "        tf.io.write_file(str(path), encoded)\n",
    "        rows.append({\"filename\": fname, \"label\": int(label)})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(PREPROCESSED_DIR / f\"{split_name}_labels.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved {len(rows)} → {split_name}\")\n",
    "\n",
    "\n",
    "# Save TRAIN\n",
    "save_image_split(final_train_images, final_train_labels, \"train\")\n",
    "\n",
    "\n",
    "# Save VAL and TEST directly (no augmentation)\n",
    "def save_split_from_tfds(ds, split_name):\n",
    "    rows = []\n",
    "    split_dir = PREPROCESSED_DIR / split_name\n",
    "\n",
    "    for i, (img, label) in enumerate(tfds.as_numpy(ds)):\n",
    "        fname = f\"{split_name}_{i:06d}.png\"\n",
    "        path = split_dir / fname\n",
    "        encoded = tf.io.encode_png(img)\n",
    "        tf.io.write_file(str(path), encoded)\n",
    "        rows.append({\"filename\": fname, \"label\": int(label)})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(PREPROCESSED_DIR / f\"{split_name}_labels.csv\", index=False)\n",
    "    print(f\"Saved {len(rows)} → {split_name}\")\n",
    "\n",
    "\n",
    "save_split_from_tfds(binary_data[\"val\"], \"val\")\n",
    "save_split_from_tfds(binary_data[\"test\"], \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(pre_dir=PREPROCESSED_DIR):\n",
    "    out = []\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        csv = pre_dir / f\"{split}_labels.csv\"\n",
    "        df = pd.read_csv(csv)\n",
    "        healthy = (df[\"label\"] == 0).sum()\n",
    "        diseased = (df[\"label\"] == 1).sum()\n",
    "        out.append({\n",
    "            \"split\": split,\n",
    "            \"healthy\": healthy,\n",
    "            \"diseased\": diseased,\n",
    "            \"total\": len(df)\n",
    "        })\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "summary_df = summarize()\n",
    "summary_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
